{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7662ff1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Check for GPU availability\n",
    "if tf.test.is_gpu_available():\n",
    "    print(\"GPU is available and ready for use.\")\n",
    "else:\n",
    "    print(\"No GPU available. Check your setup.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "740c4002-ec3a-4e09-87d5-9e3f27bdc48f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         vengo a verte pasar todos los días aporciten c...\n",
      "1         entró efectivamente el tártaro con áspero cont...\n",
      "2         reparte el señor del huerto la fruta y no ella...\n",
      "3         que para huír de un hablador de estos querría ...\n",
      "4         los lagartos los escarabajos los insectos buri...\n",
      "                                ...                        \n",
      "168518    señor don luis de santo orcaz voy a deciros pu...\n",
      "168519    todo está resuelto y por ahora os dan con la p...\n",
      "168520    la seora marquesa de leiba al recoger a la señ...\n",
      "168521    por tanto he aquí que nuevamente excitaré yo l...\n",
      "168522    porque perecerá la sabiduría de sus sabios y s...\n",
      "Name: transcript_wav2vec, Length: 168523, dtype: object\n",
      "Empty DataFrame\n",
      "Columns: [wav_filename, wav_filesize, transcript, transcript_wav2vec, levenshtein, duration, num_words, client_id, path]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "column_names = ['wav_filename',\t'wav_filesize',\t'transcript',\t'transcript_wav2vec',\t'levenshtein',\t'duration',\t'num_words','client_id', 'path']\n",
    "\n",
    "df = pd.read_csv('/srv/storage/idmctal@storage1.nancy.grid5000.fr/2023/m2/adrelingyte/data/spanish/cml_tts_dataset_spanish_v0.1/train.csv', delimiter='|')\n",
    "df.columns = column_names\n",
    "column_data = df.iloc[:, 3]\n",
    "print(column_data)\n",
    "\n",
    "# Search for the character '͡' in a specific column and handle missing values\n",
    "search_character = '͡'\n",
    "column_name = 'transcript'\n",
    "result = df[df[column_name].str.contains(search_character, na=False)]\n",
    "\n",
    "# Display the rows where the character was found\n",
    "print(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32a95f1d-810d-4b88-b2f5-f1614ec0a06e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:24000\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log\n",
      " | > min_level_db:-100\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:20\n",
      " | > fft_size:1024\n",
      " | > power:1.5\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:60\n",
      " | > signal_norm:False\n",
      " | > symmetric_norm:True\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:8000\n",
      " | > pitch_fmin:1.0\n",
      " | > pitch_fmax:640.0\n",
      " | > spec_gain:1.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:4.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:True\n",
      " | > trim_db:23.0\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:None\n",
      " | > base:2.718281828459045\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'TTS.tts.datasets' has no attribute 'custom_formatter2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/adrelingyte/workspace/DeepFake/Aine_tacotron_spanish/c.ipynb Cell 3\u001b[0m line \u001b[0;36m7\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bnancy.g5k/home/adrelingyte/workspace/DeepFake/Aine_tacotron_spanish/c.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=74'>75</a>\u001b[0m config\u001b[39m.\u001b[39maudio\u001b[39m.\u001b[39mnum_mels \u001b[39m=\u001b[39m \u001b[39m80\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bnancy.g5k/home/adrelingyte/workspace/DeepFake/Aine_tacotron_spanish/c.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=76'>77</a>\u001b[0m ap \u001b[39m=\u001b[39m AudioProcessor\u001b[39m.\u001b[39minit_from_config(audio_config)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bnancy.g5k/home/adrelingyte/workspace/DeepFake/Aine_tacotron_spanish/c.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=78'>79</a>\u001b[0m train_samples, eval_samples \u001b[39m=\u001b[39m load_tts_samples(dataset_config, eval_split\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bnancy.g5k/home/adrelingyte/workspace/DeepFake/Aine_tacotron_spanish/c.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=80'>81</a>\u001b[0m \u001b[39m# Initialize the TTSTokenizer\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bnancy.g5k/home/adrelingyte/workspace/DeepFake/Aine_tacotron_spanish/c.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=81'>82</a>\u001b[0m tokenizer, config \u001b[39m=\u001b[39m TTSTokenizer\u001b[39m.\u001b[39minit_from_config(config)\n",
      "File \u001b[0;32m~/workspace/TTS/TTS/tts/datasets/__init__.py:118\u001b[0m, in \u001b[0;36mload_tts_samples\u001b[0;34m(datasets, eval_split, formatter, eval_split_max_size, eval_split_size)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[39m# setup the right data processor\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \u001b[39mif\u001b[39;00m formatter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 118\u001b[0m     formatter \u001b[39m=\u001b[39m _get_formatter_by_name(formatter_name)\n\u001b[1;32m    119\u001b[0m \u001b[39m# load train set\u001b[39;00m\n\u001b[1;32m    120\u001b[0m meta_data_train \u001b[39m=\u001b[39m formatter(root_path, meta_file_train, ignored_speakers\u001b[39m=\u001b[39mignored_speakers)\n",
      "File \u001b[0;32m~/workspace/TTS/TTS/tts/datasets/__init__.py:166\u001b[0m, in \u001b[0;36m_get_formatter_by_name\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Returns the respective preprocessing function.\"\"\"\u001b[39;00m\n\u001b[1;32m    165\u001b[0m thismodule \u001b[39m=\u001b[39m sys\u001b[39m.\u001b[39mmodules[\u001b[39m__name__\u001b[39m]\n\u001b[0;32m--> 166\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mgetattr\u001b[39;49m(thismodule, name\u001b[39m.\u001b[39;49mlower())\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'TTS.tts.datasets' has no attribute 'custom_formatter2'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from trainer import Trainer, TrainerArgs\n",
    "import gruut\n",
    "from TTS.tts.configs.shared_configs import BaseDatasetConfig\n",
    "from TTS.tts.configs.tacotron2_config import Tacotron2Config\n",
    "from TTS.config import BaseAudioConfig, BaseDatasetConfig\n",
    "from TTS.tts.datasets import load_tts_samples\n",
    "from TTS.tts.utils.speakers import SpeakerManager\n",
    "from TTS.tts.utils.text.tokenizer import TTSTokenizer\n",
    "from TTS.utils.audio import AudioProcessor\n",
    "from TTS.tts.models.tacotron2 import Tacotron2\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "\n",
    "file_output= \"/srv/storage/idmctal@storage1.nancy.grid5000.fr/2023/m2/adrelingyte/data/spanish/cml_tts_dataset_spanish_v0.1/tmp\"\n",
    "\n",
    "output_path = \"/srv/storage/idmctal@storage1.nancy.grid5000.fr/2023/m2/adrelingyte/data/spanish/cml_tts_dataset_spanish_v0.1\"\n",
    "\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)\n",
    "    \n",
    "\n",
    "# Create a BaseDatasetConfig object\n",
    "dataset_config = BaseDatasetConfig(formatter=\"custom_formatter2\", meta_file_train=\"train.csv\", path=os.path.join(output_path))\n",
    "\n",
    "\n",
    "\n",
    "# Load the dataset using your custom formatter\n",
    "\n",
    "audio_config = BaseAudioConfig(\n",
    "    sample_rate=24000,\n",
    "    do_trim_silence=True,\n",
    "    trim_db=23.0,\n",
    "    signal_norm=False,\n",
    "    mel_fmin=0.0,\n",
    "    mel_fmax=8000,\n",
    "    spec_gain=1.0,\n",
    "    log_func=\"np.log\",\n",
    "    ref_level_db=20,\n",
    "    preemphasis=0.0,\n",
    ")\n",
    "\n",
    "# Configure your Tacotron2 model\n",
    "config = Tacotron2Config(\n",
    "    run_name=\"CTacotron2\",\n",
    "    batch_size=32,\n",
    "    eval_batch_size=16,\n",
    "    num_loader_workers=4,\n",
    "    num_eval_loader_workers=4,\n",
    "    precompute_num_workers=4,\n",
    "    run_eval=True,\n",
    "    test_delay_epochs=-1,\n",
    "    epochs=100,\n",
    "    use_phonemes=True,\n",
    "    phonemizer=\"gruut\",\n",
    "    phoneme_language=\"es\",\n",
    "    phoneme_cache_path=os.path.join(file_output, \"phoneme_cache3\"),\n",
    "    print_step=25,\n",
    "    print_eval=True,\n",
    "    mixed_precision=True,\n",
    "    output_path=file_output,\n",
    "    datasets=[dataset_config],\n",
    "    use_speaker_embedding=True,\n",
    "    min_text_len=0,\n",
    "    max_text_len=500,\n",
    "    min_audio_len=100000,  # Adjust this value based on your requirements\n",
    "    max_audio_len=400000,  # Adjust this value based on your requirements\n",
    ")\n",
    "\n",
    "config.audio.fft_size = 2048\n",
    "config.audio.win_length = 1200\n",
    "config.audio.hop_length = 256\n",
    "config.audio.num_mels = 80\n",
    "\n",
    "ap = AudioProcessor.init_from_config(audio_config)\n",
    "\n",
    "train_samples, eval_samples = load_tts_samples(dataset_config, eval_split=True)\n",
    "\n",
    "# Initialize the TTSTokenizer\n",
    "tokenizer, config = TTSTokenizer.init_from_config(config)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67957ad2-9908-4004-9226-3c5e078bca4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Init speaker_embedding layer.\n"
     ]
    }
   ],
   "source": [
    "speaker_manager = SpeakerManager()\n",
    "speaker_manager.set_ids_from_data(train_samples + eval_samples, parse_key=\"speaker_name\")\n",
    "config.num_speakers = speaker_manager.num_speakers\n",
    "\n",
    "model = Tacotron2(config, ap, tokenizer, speaker_manager=speaker_manager)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96174115-e67b-4e45-87ac-146f73b1881d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " > Training Environment:\n",
      " | > Backend: Torch\n",
      " | > Mixed precision: True\n",
      " | > Precision: fp16\n",
      " | > Num. of CPUs: 8\n",
      " | > Num. of Torch Threads: 1\n",
      " | > Torch seed: 54321\n",
      " | > Torch CUDNN: True\n",
      " | > Torch CUDNN deterministic: False\n",
      " | > Torch CUDNN benchmark: False\n",
      " | > Torch TF32 MatMul: False\n",
      " > Start Tensorboard: tensorboard --logdir=/srv/storage/idmctal@storage1.nancy.grid5000.fr/2023/m2/adrelingyte/data/spanish/cml_tts_dataset_spanish_v0.1/tmp/CTacotron2-November-04-2023_06+11PM-5cf4ea1\n",
      "\n",
      " > Model has 32649842 parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > `speakers.pth` is saved to /srv/storage/idmctal@storage1.nancy.grid5000.fr/2023/m2/adrelingyte/data/spanish/cml_tts_dataset_spanish_v0.1/tmp/CTacotron2-November-04-2023_06+11PM-5cf4ea1/speakers.pth.\n",
      " > `speakers_file` is updated in the config.json.\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    TrainerArgs(), config, output_path, model=model, train_samples=train_samples, eval_samples=eval_samples\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a854a976-d046-4449-9986-acf241937fd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 0/100\u001b[0m\n",
      " --> /srv/storage/idmctal@storage1.nancy.grid5000.fr/2023/m2/adrelingyte/data/spanish/cml_tts_dataset_spanish_v0.1/tmp/CTacotron2-November-04-2023_06+11PM-5cf4ea1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "> DataLoader initialization\n",
      "| > Tokenizer:\n",
      "\t| > add_blank: False\n",
      "\t| > use_eos_bos: False\n",
      "\t| > use_phonemes: True\n",
      "\t| > phonemizer:\n",
      "\t\t| > phoneme language: es\n",
      "\t\t| > phoneme backend: gruut\n",
      "| > Number of instances : 166838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m > TRAINING (2023-11-04 18:11:56) \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " | > Preprocessing samples\n",
      " | > Max text length: 305\n",
      " | > Min text length: 0\n",
      " | > Avg text length: 137.913679273466\n",
      " | \n",
      " | > Max audio length: 399382.0\n",
      " | > Min audio length: 100821.0\n",
      " | > Avg audio length: 245005.40084841967\n",
      " | > Num. instances discarded samples: 32942\n",
      " | > Batch group size: 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adrelingyte/.local/lib/python3.9/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > SSIM loss is out-of-range -inf, setting it 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m   --> TIME: 2023-11-04 18:26:14 -- STEP: 0/4185 -- GLOBAL_STEP: 0\u001b[0m\n",
      "     | > decoder_loss: 44.86867904663086  (44.86867904663086)\n",
      "     | > postnet_loss: 46.83922576904297  (46.83922576904297)\n",
      "     | > stopnet_loss: 0.6435643434524536  (0.6435643434524536)\n",
      "     | > ga_loss: 0.006162174046039581  (0.006162174046039581)\n",
      "     | > decoder_diff_spec_loss: 0.4541545510292053  (0.4541545510292053)\n",
      "     | > postnet_diff_spec_loss: 4.502472400665283  (4.502472400665283)\n",
      "     | > decoder_ssim_loss: 0.8203125  (0.8203125)\n",
      "     | > postnet_ssim_loss: 0.0  (0.0)\n",
      "     | > loss: 25.04558563232422  (25.04558563232422)\n",
      "     | > align_error: 0.983642578125  (0.983642578125)\n",
      "     | > grad_norm: tensor(5.7063)  (tensor(5.7063))\n",
      "     | > current_lr: 2.5000000000000002e-08 \n",
      "     | > step_time: 852.0242  (852.0241842269897)\n",
      "     | > loader_time: 5.4737  (5.473690986633301)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: audio amplitude out of range, auto clipped.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d1ec9a-14d8-4bea-b9cb-44394910a815",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
