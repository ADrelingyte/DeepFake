{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from trainer import Trainer, TrainerArgs\n",
    "from TTS.config.shared_configs import BaseAudioConfig\n",
    "from TTS.tts.configs.shared_configs import BaseDatasetConfig, CapacitronVAEConfig\n",
    "from TTS.tts.configs.tacotron2_config import Tacotron2Config\n",
    "from TTS.tts.datasets import load_tts_samples\n",
    "from TTS.tts.models.tacotron2 import Tacotron2\n",
    "from TTS.tts.utils.text.tokenizer import TTSTokenizer\n",
    "from TTS.utils.audio import AudioProcessor\n",
    "from TTS.tts.utils.speakers import SpeakerManager\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "\n",
    "file_output = \"/srv/storage/idmctal@storage1.nancy.grid5000.fr/2023/m2/adrelingyte/data/spanish/cml_tts_dataset_spanish_v0.1/tmp\"\n",
    "\n",
    "output_path = \"/srv/storage/idmctal@storage1.nancy.grid5000.fr/2023/m2/adrelingyte/data/spanish/cml_tts_dataset_spanish_v0.1\"\n",
    "\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)\n",
    "\n",
    "# Using LJSpeech like dataset processing for the blizzard dataset\n",
    "dataset_config = BaseDatasetConfig(formatter=\"custom_formatter2\", meta_file_train=\"train.csv\", path=os.path.join(output_path))\n",
    "\n",
    "\n",
    "audio_config = BaseAudioConfig(\n",
    "    sample_rate=24000,\n",
    "    do_trim_silence=True,\n",
    "    trim_db=60.0,\n",
    "    signal_norm=False,\n",
    "    mel_fmin=0.0,\n",
    "    mel_fmax=11025,\n",
    "    spec_gain=1.0,\n",
    "    log_func=\"np.log\",\n",
    "    ref_level_db=20,\n",
    "    preemphasis=0.0,\n",
    ")\n",
    "\n",
    "# Using the standard Capacitron config\n",
    "capacitron_config = CapacitronVAEConfig(capacitron_VAE_loss_alpha=1.0, capacitron_capacity=50)\n",
    "\n",
    "config = Tacotron2Config(\n",
    "    run_name=\"Capacitron-Tacotron2\",\n",
    "    audio=audio_config,\n",
    "    capacitron_vae=capacitron_config,\n",
    "    use_capacitron_vae=True,\n",
    "    batch_size=16,  # Tune this to your gpu\n",
    "    max_audio_len=36 * 10000,  # Tune this to your gpu\n",
    "    min_audio_len=23 * 10000,\n",
    "    eval_batch_size=4,\n",
    "    num_loader_workers=4,\n",
    "    num_eval_loader_workers=4,\n",
    "    precompute_num_workers=4,\n",
    "    run_eval=True,\n",
    "    test_delay_epochs=9,\n",
    "    ga_alpha=0.0,\n",
    "    r=2,\n",
    "    optimizer=\"CapacitronOptimizer\",\n",
    "    optimizer_params={\"RAdam\": {\"betas\": [0.9, 0.998], \"weight_decay\": 1e-6}, \"SGD\": {\"lr\": 1e-5, \"momentum\": 0.9}},\n",
    "    attention_type=\"dynamic_convolution\",\n",
    "    grad_clip=0.0,  # Important! We overwrite the standard grad_clip with capacitron_grad_clip\n",
    "    double_decoder_consistency=False,\n",
    "    epochs=10,\n",
    "    use_phonemes=True,\n",
    "    phoneme_language=\"es\",\n",
    "    phonemizer=\"gruut\",\n",
    "    phoneme_cache_path=os.path.join(file_output, \"phoneme_cache10\"),\n",
    "    stopnet_pos_weight=15,\n",
    "    print_step=25,\n",
    "    print_eval=True,\n",
    "    mixed_precision=False,\n",
    "    seq_len_norm=True,\n",
    "    use_speaker_embedding=True,\n",
    "    output_path=file_output,\n",
    "    datasets=[dataset_config],\n",
    "    lr=1e-3,\n",
    "    lr_scheduler=\"StepwiseGradualLR\",\n",
    "    lr_scheduler_params={\n",
    "        \"gradual_learning_rates\": [\n",
    "            [0, 1e-3],\n",
    "            [2e4, 5e-4],\n",
    "            [4e5, 3e-4],\n",
    "            [6e4, 1e-4],\n",
    "            [8e4, 5e-5],\n",
    "        ]\n",
    "    },\n",
    "    scheduler_after_epoch=False,  # scheduler doesn't work without this flag\n",
    "    # Need to experiment with these below for capacitron\n",
    "    loss_masking=False,\n",
    "    decoder_loss_alpha=1.0,\n",
    "    postnet_loss_alpha=1.0,\n",
    "    postnet_diff_spec_alpha=0.0,\n",
    "    decoder_diff_spec_alpha=0.0,\n",
    "    decoder_ssim_alpha=0.0,\n",
    "    postnet_ssim_alpha=0.0,\n",
    ")\n",
    "\n",
    "## INITIALIZE THE AUDIO PROCESSOR\n",
    "# Audio processor is used for feature extraction and audio I/O.\n",
    "# It mainly serves to the dataloader and the training loggers.\n",
    "ap = AudioProcessor.init_from_config(config)\n",
    "\n",
    "# INITIALIZE THE TOKENIZER\n",
    "# Tokenizer is used to convert text to sequences of token IDs.\n",
    "# If characters are not defined in the config, default characters are passed to the config\n",
    "tokenizer, config = TTSTokenizer.init_from_config(config)\n",
    "\n",
    "# LOAD DATA SAMPLES\n",
    "# Each sample is a list of ```[text, audio_file_path, speaker_name]```\n",
    "# You can define your custom sample loader returning the list of samples.\n",
    "# Or define your custom formatter and pass it to the `load_tts_samples`.\n",
    "# Check `TTS.tts.datasets.load_tts_samples` for more details.\n",
    "train_samples, eval_samples = load_tts_samples(\n",
    "    dataset_config,\n",
    "    eval_split=True,\n",
    "    eval_split_max_size=config.eval_split_max_size,\n",
    "    eval_split_size=config.eval_split_size,\n",
    ")\n",
    "\n",
    "# init speaker manager for multi-speaker training\n",
    "# it mainly handles speaker-id to speaker-name for the model and the data-loader\n",
    "speaker_manager = SpeakerManager()\n",
    "speaker_manager.set_ids_from_data(train_samples + eval_samples, parse_key=\"speaker_name\")\n",
    "\n",
    "# init model\n",
    "model = Tacotron2(config, ap, tokenizer, speaker_manager)\n",
    "\n",
    "# INITIALIZE THE TRAINER\n",
    "# Trainer provides a generic API to train all the üê∏TTS models with all its perks like mixed-precision training,\n",
    "# distributed training, etc.\n",
    "trainer = Trainer(\n",
    "    TrainerArgs(), config, output_path, model=model, train_samples=train_samples, eval_samples=eval_samples\n",
    ")\n",
    "\n",
    "# AND... 3,2,1... üöÄ\n",
    "trainer.fit()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
