{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zBdLjKfwgoJv",
        "outputId": "7f87538b-a44f-4b1e-b11c-4ffa47c2fcd8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VtkZJBacy8O1",
        "outputId": "119ef2cf-df2a-4ef7-e64f-404849c82b1d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.33.*->TTS) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.33.*->TTS) (0.18.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.33.*->TTS) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.33.*->TTS) (2.31.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.33.*->TTS) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.33.*->TTS) (0.4.0)\n",
            "Requirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.10/dist-packages (from umap-learn==0.5.*->TTS) (0.5.10)\n",
            "Requirement already satisfied: tbb>=2019.0 in /usr/local/lib/python3.10/dist-packages (from umap-learn==0.5.*->TTS) (2021.10.0)\n",
            "Requirement already satisfied: docopt>=0.6.2 in /usr/local/lib/python3.10/dist-packages (from num2words->TTS) (0.6.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.0,>=1.4->TTS) (2023.3.post1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->TTS) (1.12)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->TTS) (2.1.0)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (from k-diffusion->TTS) (0.24.1)\n",
            "Requirement already satisfied: clean-fid in /usr/local/lib/python3.10/dist-packages (from k-diffusion->TTS) (0.1.35)\n",
            "Requirement already satisfied: clip-anytorch in /usr/local/lib/python3.10/dist-packages (from k-diffusion->TTS) (2.5.2)\n",
            "Requirement already satisfied: jsonmerge in /usr/local/lib/python3.10/dist-packages (from k-diffusion->TTS) (1.9.2)\n",
            "Requirement already satisfied: kornia in /usr/local/lib/python3.10/dist-packages (from k-diffusion->TTS) (0.7.0)\n",
            "Requirement already satisfied: resize-right in /usr/local/lib/python3.10/dist-packages (from k-diffusion->TTS) (0.0.2)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from k-diffusion->TTS) (0.19.3)\n",
            "Requirement already satisfied: torchdiffeq in /usr/local/lib/python3.10/dist-packages (from k-diffusion->TTS) (0.2.3)\n",
            "Requirement already satisfied: torchsde in /usr/local/lib/python3.10/dist-packages (from k-diffusion->TTS) (0.2.6)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from k-diffusion->TTS) (0.16.0+cu118)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (from k-diffusion->TTS) (0.16.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from trainer->TTS) (5.9.5)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from trainer->TTS) (2.9.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile==0.12.*->TTS) (2.21)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.10/dist-packages (from dateparser~=1.1.0->gruut[de,es,fr]==2.2.3->TTS) (5.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.0->flask==2.*->TTS) (2.1.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from jsonlines~=1.2.0->gruut[de,es,fr]==2.2.3->TTS) (1.16.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa==0.10.*->TTS) (3.11.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.33.*->TTS) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.33.*->TTS) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.33.*->TTS) (2023.7.22)\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.10/dist-packages (from clip-anytorch->k-diffusion->TTS) (6.1.1)\n",
            "Requirement already satisfied: jsonschema>2.4.0 in /usr/local/lib/python3.10/dist-packages (from jsonmerge->k-diffusion->TTS) (4.19.2)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->k-diffusion->TTS) (2.31.6)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->k-diffusion->TTS) (2023.9.26)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->k-diffusion->TTS) (1.4.1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7->TTS) (1.3.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->trainer->TTS) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard->trainer->TTS) (1.59.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard->trainer->TTS) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard->trainer->TTS) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->trainer->TTS) (3.5.1)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->trainer->TTS) (3.19.6)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->trainer->TTS) (67.7.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->trainer->TTS) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->trainer->TTS) (1.8.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.10/dist-packages (from tensorboard->trainer->TTS) (0.41.3)\n",
            "Requirement already satisfied: trampoline>=0.1.2 in /usr/local/lib/python3.10/dist-packages (from torchsde->k-diffusion->TTS) (0.1.2)\n",
            "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb->k-diffusion->TTS) (3.1.40)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb->k-diffusion->TTS) (1.34.0)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb->k-diffusion->TTS) (0.4.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb->k-diffusion->TTS) (1.3.3)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb->k-diffusion->TTS) (1.4.4)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from GitPython!=3.1.29,>=1.0.0->wandb->k-diffusion->TTS) (4.0.11)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->trainer->TTS) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->trainer->TTS) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->trainer->TTS) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->trainer->TTS) (1.3.1)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>2.4.0->jsonmerge->k-diffusion->TTS) (2023.7.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>2.4.0->jsonmerge->k-diffusion->TTS) (0.30.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>2.4.0->jsonmerge->k-diffusion->TTS) (0.11.0)\n",
            "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.10/dist-packages (from ftfy->clip-anytorch->k-diffusion->TTS) (0.2.9)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb->k-diffusion->TTS) (5.0.1)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->trainer->TTS) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->trainer->TTS) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install TTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6GcWxnhnOEQs"
      },
      "outputs": [],
      "source": [
        "!apt-get install espeak-ng"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r03LI5ntYoVr"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow==2.9.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-KcxpnDdv_W",
        "outputId": "c443a957-f3eb-48ef-e628-c07d89a03e6a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TTS                              0.20.1                /usr/local/lib/python3.10/dist-packages pip\n"
          ]
        }
      ],
      "source": [
        "!pip list -v | grep TTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_LX2lwYVd7s6",
        "outputId": "d2e0a427-6068-4a9a-9b6c-5e22ee82a556"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name: TTS\n",
            "Version: 0.20.1\n",
            "Summary: Deep learning for Text to Speech by Coqui.\n",
            "Home-page: https://github.com/coqui-ai/TTS\n",
            "Author: Eren Gölge\n",
            "Author-email: egolge@coqui.ai\n",
            "License: MPL-2.0\n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: aiohttp, anyascii, bangla, bnnumerizer, bnunicodenormalizer, coqpit, cython, einops, encodec, flask, fsspec, g2pkk, gruut, hangul-romanize, inflect, jamo, jieba, k-diffusion, librosa, matplotlib, nltk, num2words, numba, numpy, packaging, pandas, pypinyin, pysbd, pyyaml, scikit-learn, scipy, soundfile, torch, torchaudio, tqdm, trainer, transformers, umap-learn, unidecode\n",
            "Required-by: \n"
          ]
        }
      ],
      "source": [
        "!pip show TTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "snAe9sZDcqa8",
        "outputId": "95f97bf9-d35b-4095-83a9-afe596ba0836"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Recursively copying the input folder...\n",
            "Resampling the audio files...\n",
            "Found 100 files...\n",
            "100% 100/100 [00:39<00:00,  2.56it/s]\n",
            "Done !\n"
          ]
        }
      ],
      "source": [
        "!python  /usr/local/lib/python3.10/dist-packages/TTS/bin/resample.py --input_dir /content/drive/MyDrive/Software_proj/Tacatron/tts_train_dir/wavs/ \\\n",
        "  --output_sr 22050 \\\n",
        "  --output_dir /content/drive/MyDrive/Software_proj/Tacatron/tts_train_dir/wavs2/ \\\n",
        "  --file_ext wav \\\n",
        "  --n_jobs 24"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U077VFlcFj4B",
        "outputId": "eae98bac-9fad-4ac8-e3c3-585a0d090a9c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " > Setting up Audio Processor...\n",
            " | > sample_rate:22050\n",
            " | > resample:False\n",
            " | > num_mels:80\n",
            " | > log_func:np.log\n",
            " | > min_level_db:-100\n",
            " | > frame_shift_ms:None\n",
            " | > frame_length_ms:None\n",
            " | > ref_level_db:20\n",
            " | > fft_size:768\n",
            " | > power:1.5\n",
            " | > preemphasis:0.0\n",
            " | > griffin_lim_iters:60\n",
            " | > signal_norm:False\n",
            " | > symmetric_norm:True\n",
            " | > mel_fmin:0\n",
            " | > mel_fmax:8000\n",
            " | > pitch_fmin:1.0\n",
            " | > pitch_fmax:640.0\n",
            " | > spec_gain:1.0\n",
            " | > stft_pad_mode:reflect\n",
            " | > max_norm:4.0\n",
            " | > clip_norm:True\n",
            " | > do_trim_silence:True\n",
            " | > trim_db:24.0\n",
            " | > do_sound_norm:False\n",
            " | > do_amp_to_db_linear:True\n",
            " | > do_amp_to_db_mel:True\n",
            " | > do_rms_norm:False\n",
            " | > db_level:None\n",
            " | > stats_path:None\n",
            " | > base:2.718281828459045\n",
            " | > hop_length:256\n",
            " | > win_length:768\n",
            " | > Found 100 files in /content/drive/MyDrive/Software_proj/Tacatron/tts_train_dir\n",
            "Number of training samples: 99\n",
            "Number of evaluation samples: 1\n",
            " > Init speaker_embedding layer.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " > Training Environment:\n",
            " | > Backend: Torch\n",
            " | > Mixed precision: False\n",
            " | > Precision: float32\n",
            " | > Current device: 0\n",
            " | > Num. of GPUs: 1\n",
            " | > Num. of CPUs: 2\n",
            " | > Num. of Torch Threads: 1\n",
            " | > Torch seed: 54321\n",
            " | > Torch CUDNN: True\n",
            " | > Torch CUDNN deterministic: False\n",
            " | > Torch CUDNN benchmark: False\n",
            " | > Torch TF32 MatMul: False\n",
            " > Start Tensorboard: tensorboard --logdir=/content/drive/MyDrive/Software_proj/Tacatron/tts_train_dir/run-November-08-2023_02+54PM-0000000\n",
            "\n",
            " > Model has 56706292 parameters\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " > `speakers.pth` is saved to /content/drive/MyDrive/Software_proj/Tacatron/tts_train_dir/run-November-08-2023_02+54PM-0000000/speakers.pth.\n",
            " > `speakers_file` is updated in the config.json.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 0/1000\u001b[0m\n",
            " --> /content/drive/MyDrive/Software_proj/Tacatron/tts_train_dir/run-November-08-2023_02+54PM-0000000\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\u001b[1m > TRAINING (2023-11-08 14:54:36) \u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " > Number of output frames: 6\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: False\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: pl\n",
            "\t\t| > phoneme backend: espeak\n",
            "| > Number of instances : 99\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 250\n",
            " | > Min text length: 115\n",
            " | > Avg text length: 184.26262626262627\n",
            " | \n",
            " | > Max audio length: 329670.0\n",
            " | > Min audio length: 220522.0\n",
            " | > Avg audio length: 271263.9696969697\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-11-08 14:54:51 -- STEP: 0/2 -- GLOBAL_STEP: 0\u001b[0m\n",
            "     | > decoder_loss: 40.21834182739258  (40.21834182739258)\n",
            "     | > postnet_loss: 42.37211227416992  (42.37211227416992)\n",
            "     | > stopnet_loss: 0.7851433753967285  (0.7851433753967285)\n",
            "     | > decoder_coarse_loss: 40.200164794921875  (40.200164794921875)\n",
            "     | > decoder_ddc_loss: 0.0013703416334465146  (0.0013703416334465146)\n",
            "     | > ga_loss: 0.0016760959988459945  (0.0016760959988459945)\n",
            "     | > loss: 31.491519927978516  (31.491519927978516)\n",
            "     | > align_error: 0.9948520567268133  (0.9948520567268133)\n",
            "     | > grad_norm: tensor(2.6958, device='cuda:0')  (tensor(2.6958, device='cuda:0'))\n",
            "     | > current_lr: 3e-05 \n",
            "     | > step_time: 8.7681  (8.768144369125366)\n",
            "     | > loader_time: 6.0354  (6.035442113876343)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "warning: audio amplitude out of range, auto clipped.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: False\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: pl\n",
            "\t\t| > phoneme backend: espeak\n",
            "| > Number of instances : 1\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 180\n",
            " | > Min text length: 180\n",
            " | > Avg text length: 180.0\n",
            " | \n",
            " | > Max audio length: 232209.0\n",
            " | > Min audio length: 232209.0\n",
            " | > Avg audio length: 232209.0\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[1m   --> STEP: 0\u001b[0m\n",
            "     | > decoder_loss: 28.862407684326172  (28.862407684326172)\n",
            "     | > postnet_loss: 28.824796676635742  (28.824796676635742)\n",
            "     | > stopnet_loss: 0.9682840704917908  (0.9682840704917908)\n",
            "     | > decoder_coarse_loss: 28.829214096069336  (28.829214096069336)\n",
            "     | > decoder_ddc_loss: 0.00012419026461429894  (0.00012419026461429894)\n",
            "     | > ga_loss: 0.001495089614763856  (0.001495089614763856)\n",
            "     | > loss: 22.604894638061523  (22.604894638061523)\n",
            "     | > align_error: 0.9951699892990291  (0.9951699892990291)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "warning: audio amplitude out of range, auto clipped.\n",
            " | > Synthesizing test sentences.\n",
            "mrɔvˈiskɔ jɛzd bˈardʑɛj vʲˈɔskɔ̃.\n",
            " [!] Character '̃' not found in the vocabulary. Discarding it.\n",
            "   > Decoder stopped with `max_decoder_steps` 100000\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "from trainer import Trainer, TrainerArgs\n",
        "\n",
        "from TTS.config.shared_configs import BaseAudioConfig\n",
        "from TTS.tts.configs.shared_configs import BaseDatasetConfig\n",
        "from TTS.tts.configs.tacotron2_config import Tacotron2Config\n",
        "from TTS.tts.datasets import load_tts_samples\n",
        "from TTS.tts.models.tacotron2 import Tacotron2\n",
        "from TTS.tts.utils.speakers import SpeakerManager\n",
        "from TTS.tts.utils.text.tokenizer import TTSTokenizer\n",
        "from TTS.utils.audio import AudioProcessor\n",
        "\n",
        "import torch\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "output_path = \"/content/drive/MyDrive/Software_proj/Tacatron/tts_train_dir/\"\n",
        "\n",
        "data_path = \"/content/drive/MyDrive/Software_proj/Tacatron/tts_train_dir/\"\n",
        "\n",
        "# Using LJSpeech like dataset processing for the blizzard dataset\n",
        "dataset_config = BaseDatasetConfig(\n",
        "    formatter=\"ljspeech_test\",\n",
        "    meta_file_train=\"train.csv\",\n",
        "    path=data_path,\n",
        ")\n",
        "\n",
        "\n",
        "audio_config = BaseAudioConfig(\n",
        "    fft_size=768,\n",
        "    win_length=768,\n",
        "    sample_rate=22050,\n",
        "    resample=False,  # Resample to 22050 Hz. It slows down training. Use `TTS/bin/resample.py` to pre-resample and set this False for faster training.\n",
        "    do_trim_silence=True,\n",
        "    trim_db=24.0,\n",
        "    signal_norm=False,\n",
        "    mel_fmin=0.0,\n",
        "    mel_fmax=8000,\n",
        "    ref_level_db=20,\n",
        "    spec_gain=1.0,\n",
        "    log_func=\"np.log\",\n",
        "    preemphasis=0.0,\n",
        "\n",
        ")\n",
        "\n",
        "config = Tacotron2Config(  # This is the config that is saved for the future use\n",
        "    audio=audio_config,\n",
        "    max_decoder_steps=100000,\n",
        "    batch_size=64,\n",
        "    eval_batch_size=16,\n",
        "    num_loader_workers=4,\n",
        "    num_eval_loader_workers=4,\n",
        "    run_eval=True,\n",
        "    test_delay_epochs=-1,\n",
        "    r=6,\n",
        "    gradual_training=[[0, 6, 64], [10000, 4, 32], [50000, 3, 32], [100000, 2, 32]],\n",
        "    double_decoder_consistency=True,\n",
        "    #r=2,\n",
        "    #gradual_training=[[0, 6, 48], [10000, 4, 32], [50000, 3, 32], [100000, 2, 32]],\n",
        "    #double_decoder_consistency=False,\n",
        "    epochs=1000,\n",
        "    phonemizer=\"espeak\",\n",
        "    use_phonemes=True,\n",
        "    phoneme_language=\"pl\",\n",
        "    phoneme_cache_path=os.path.join(output_path, \"phoneme_cache\"),\n",
        "    print_step=150,\n",
        "    print_eval=True,\n",
        "    mixed_precision=False,\n",
        "    #115,250\n",
        "    min_text_len=115,\n",
        "    max_text_len=250,\n",
        "    min_audio_len=22050 * 0,\n",
        "    max_audio_len=22050 * 33,\n",
        "    output_path=output_path,\n",
        "    datasets=[dataset_config],\n",
        "    use_speaker_embedding=True,  # set this to enable multi-sepeaker training\n",
        "    decoder_ssim_alpha=0.0,  # disable ssim losses that causes NaN for some runs.\n",
        "    postnet_ssim_alpha=0.0,\n",
        "    postnet_diff_spec_alpha=0.0,\n",
        "    decoder_diff_spec_alpha=0.0,\n",
        "    attention_norm=\"softmax\",\n",
        "    optimizer=\"Adam\",\n",
        "    lr_scheduler=None,\n",
        "    lr=3e-5,\n",
        "    test_sentences=[\n",
        "        \"Mrowisko jest bardziej wioską.\",\n",
        "        \"Zejście po pionowej łodydze.\",\n",
        "        \"że choćby mi przyszło porzucić cię.\",\n",
        "        \"Pod domami płynie rzeka tłumu. Ulica jest szeroka jak bulwar wielkomiejski.\",\n",
        "        \"Były to ogromne wiechcie piór.\",\n",
        "    ]\n",
        ")\n",
        "\n",
        "## INITIALIZE THE AUDIO PROCESSOR\n",
        "# Audio processor is used for feature extraction and audio I/O.\n",
        "# It mainly serves to the dataloader and the training loggers.\n",
        "ap = AudioProcessor.init_from_config(config)\n",
        "\n",
        "# INITIALIZE THE TOKENIZER\n",
        "# Tokenizer is used to convert text to sequences of token IDs.\n",
        "# If characters are not defined in the config, default characters are passed to the config\n",
        "tokenizer, config = TTSTokenizer.init_from_config(config)\n",
        "\n",
        "# LOAD DATA SAMPLES\n",
        "# Each sample is a list of ```[text, audio_file_path, speaker_name]```\n",
        "# You can define your custom sample loader returning the list of samples.\n",
        "# Or define your custom formatter and pass it to the `load_tts_samples`.\n",
        "# Check `TTS.tts.datasets.load_tts_samples` for more details.\n",
        "train_samples, eval_samples = load_tts_samples(\n",
        "    dataset_config,\n",
        "    eval_split=True,\n",
        "    eval_split_max_size=config.eval_split_max_size,\n",
        "    eval_split_size=config.eval_split_size,\n",
        ")\n",
        "\n",
        "\n",
        "print(\"Number of training samples:\", len(train_samples))\n",
        "print(\"Number of evaluation samples:\", len(eval_samples))\n",
        "\n",
        "\n",
        "# Handle Empty Dataset\n",
        "if not train_samples or not eval_samples:\n",
        "    print(\"Error: Training or evaluation samples are empty.\")\n",
        "\n",
        "# init speaker manager for multi-speaker training\n",
        "# it mainly handles speaker-id to speaker-name for the model and the data-loader\n",
        "speaker_manager = SpeakerManager()\n",
        "speaker_manager.set_ids_from_data(train_samples + eval_samples, parse_key=\"speaker_name\")\n",
        "\n",
        "# init model\n",
        "model = Tacotron2(config, ap, tokenizer, speaker_manager)\n",
        "\n",
        "# INITIALIZE THE TRAINER\n",
        "# Trainer provides a generic API to train all the 🐸TTS models with all its perks like mixed-precision training,\n",
        "# distributed training, etc.\n",
        "trainer = Trainer(\n",
        "    TrainerArgs(), config, output_path, model=model, train_samples=train_samples, eval_samples=eval_samples\n",
        ")\n",
        "# AND... 3,2,1... 🚀\n",
        "trainer.fit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dPEsuwPkiZB_",
        "outputId": "75bdfdd7-6053-4c4d-a723-d55ea53f192e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['/content/drive/MyDrive/Software_proj/Tacatron/tts_train_dir/run-November-08-2023_01+01PM-0000000/best_model.pth', '/content/drive/MyDrive/Software_proj/Tacatron/tts_train_dir/run-November-08-2023_01+01PM-0000000/best_model_210.pth', '/content/drive/MyDrive/Software_proj/Tacatron/tts_train_dir/run-November-08-2023_01+01PM-0000000/speakers.pth', '/content/drive/MyDrive/Software_proj/Tacatron/tts_train_dir/run-November-08-2023_02+50PM-0000000/speakers.pth', '/content/drive/MyDrive/Software_proj/Tacatron/tts_train_dir/run-November-08-2023_02+54PM-0000000/speakers.pth'] ['/content/drive/MyDrive/Software_proj/Tacatron/tts_train_dir/run-November-08-2023_01+01PM-0000000/config.json', '/content/drive/MyDrive/Software_proj/Tacatron/tts_train_dir/run-November-08-2023_02+50PM-0000000/config.json', '/content/drive/MyDrive/Software_proj/Tacatron/tts_train_dir/run-November-08-2023_02+54PM-0000000/config.json']\n"
          ]
        }
      ],
      "source": [
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
        "\n",
        "import glob, os\n",
        "output_path = \"/content/drive/MyDrive/Software_proj/Tacatron/tts_train_dir/\"\n",
        "ckpts = sorted([f for f in glob.glob(output_path+\"/*/*.pth\")])\n",
        "configs = sorted([f for f in glob.glob(output_path+\"/*/*.json\")])\n",
        "\n",
        "print(ckpts, configs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Io5IDqbfUZkj",
        "outputId": "449dc07c-4f05-4905-d85f-652be4fa8e89"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " > Using model: tacotron2\n",
            " > Setting up Audio Processor...\n",
            " | > sample_rate:22050\n",
            " | > resample:False\n",
            " | > num_mels:80\n",
            " | > log_func:np.log\n",
            " | > min_level_db:-100\n",
            " | > frame_shift_ms:None\n",
            " | > frame_length_ms:None\n",
            " | > ref_level_db:20\n",
            " | > fft_size:768\n",
            " | > power:1.5\n",
            " | > preemphasis:0.0\n",
            " | > griffin_lim_iters:60\n",
            " | > signal_norm:False\n",
            " | > symmetric_norm:True\n",
            " | > mel_fmin:0\n",
            " | > mel_fmax:8000.0\n",
            " | > pitch_fmin:1.0\n",
            " | > pitch_fmax:640.0\n",
            " | > spec_gain:1.0\n",
            " | > stft_pad_mode:reflect\n",
            " | > max_norm:4.0\n",
            " | > clip_norm:True\n",
            " | > do_trim_silence:True\n",
            " | > trim_db:24\n",
            " | > do_sound_norm:False\n",
            " | > do_amp_to_db_linear:True\n",
            " | > do_amp_to_db_mel:True\n",
            " | > do_rms_norm:False\n",
            " | > db_level:None\n",
            " | > stats_path:None\n",
            " | > base:2.718281828459045\n",
            " | > hop_length:256\n",
            " | > win_length:768\n",
            " > Init speaker_embedding layer.\n",
            " > Model's reduction rate `r` is set to: 2\n",
            " > Text: a oprócz tego kilka tysięcy i namioty.\n",
            " > Text splitted to sentences.\n",
            "['a oprócz tego kilka tysięcy i namioty.']\n",
            "   > Decoder stopped with `max_decoder_steps` 10000\n",
            " > Processing time: 185.56279015541077\n",
            " > Real-time factor: 0.797634252884122\n",
            " > Saving output to out.wav\n"
          ]
        }
      ],
      "source": [
        "model_path = ckpts[0]\n",
        "config_path = configs[0]\n",
        "speaker_idx = 'ljspeech-9'\n",
        "\n",
        "!tts --text \"a oprócz tego kilka tysięcy i namioty.\" \\\n",
        "      --model_path $model_path \\\n",
        "      --config_path $config_path \\\n",
        "      --speaker_idx $speaker_idx \\\n",
        "      --out_path out.wav"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
